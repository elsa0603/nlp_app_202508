# Streamlit + yfinance + Hugging Faceï¼šè‚¡åƒ¹èˆ‡è¼¿æƒ…åˆ†æå„€è¡¨æ¿
# -------------------------------------------------------------
# ä½¿ç”¨æ–¹å¼ï¼š
# 1) å®‰è£å¥—ä»¶ï¼š
#    pip install streamlit yfinance plotly pandas xlsxwriter transformers torch sentencepiece
# 2) åŸ·è¡Œï¼š
#    streamlit run app.py
# -------------------------------------------------------------

import datetime as dt
from typing import List, Dict, Tuple

import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import streamlit as st
import yfinance as yf

# HF
from transformers import pipeline

st.set_page_config(page_title="Stock + Sentiment Dashboard", layout="wide")

# -----------------------------
# Sidebarï¼šåƒæ•¸
# -----------------------------
st.sidebar.title("è¨­å®š")
mode = st.sidebar.radio("æ¨¡å¼", ["å–®ä¸€æ¨™çš„", "å¤šæ¨™çš„æ¯”è¼ƒ"], index=0)

if mode == "å¤šæ¨™çš„æ¯”è¼ƒ":
    tickers: List[str] = st.sidebar.text_input(
        "è¼¸å…¥ä»£è™Ÿ (é€—è™Ÿåˆ†éš”)",
        value="AAPL, TSLA, NVDA",
        help="ä¾‹å¦‚ï¼šAAPL, TSLA æˆ– ^TWII, 2330.TW (å°ç©é›»)"
    ).replace(" ", "").split(",")
else:
    ticker = st.sidebar.text_input(
        "å–®ä¸€ä»£è™Ÿ",
        value="AAPL",
        help="ä¾‹å¦‚ï¼šAAPLã€TSLAã€NVDAã€2330.TWã€^GSPC"
    ).strip()
    tickers = [ticker]

# æ—¥æœŸå€é–“
end_date = st.sidebar.date_input("çµæŸæ—¥", dt.date.today())
start_default = end_date - dt.timedelta(days=365)
start_date = st.sidebar.date_input("é–‹å§‹æ—¥", start_default)

# K ç·šé–“éš”
interval = st.sidebar.selectbox(
    "å–æ¨£é »ç‡ (interval)",
    options=["1d", "1wk", "1mo"],
    index=0,
    help="æ—¥/é€±/æœˆè³‡æ–™"
)

# ç§»å‹•å¹³å‡èˆ‡åœ–è¡¨
ma_1 = st.sidebar.number_input("MA çª—å£1", min_value=2, max_value=250, value=20)
ma_2 = st.sidebar.number_input("MA çª—å£2", min_value=2, max_value=500, value=50)
show_volume = st.sidebar.checkbox("é¡¯ç¤ºæˆäº¤é‡", value=True)

# è¼¿æƒ…ï¼ˆHugging Faceï¼‰
st.sidebar.markdown("---")
st.sidebar.subheader("è¼¿æƒ…åˆ†æï¼ˆHugging Faceï¼‰")
# é è¨­ä½¿ç”¨å¤šèªè¨€ä¸‰åˆ†é¡ï¼šnegative / neutral / positive
# å…¶ä»–å¯ç”¨ï¼šnlptown/bert-base-multilingual-uncased-sentiment (1~5æ˜Ÿ) ç­‰
model_name = st.sidebar.text_input(
    "æ¨¡å‹åç¨±",
    value="cardiffnlp/twitter-xlm-roberta-base-sentiment",
    help="å»ºè­°å¤šèªè¨€æ¨¡å‹ä»¥ä¾¿ä¸­è‹±ä¸¦ç”¨"
)
max_items_news = st.sidebar.slider("åˆ†ææœ€æ–°æ–°è(ç­†)", 0, 50, 20, help="0 ä»£è¡¨ä¸æŠ“æ–°è")
user_text = st.sidebar.text_area("æˆ–è‡ªè¡Œè¼¸å…¥å¾…åˆ†ææ–‡å­—(æ¯è¡Œä¸€å‰‡)")


# -----------------------------
# å·¥å…·å‡½å¼
# -----------------------------

@st.cache_data(ttl=3600)
def _valid_range(s: dt.date, e: dt.date) -> bool:
    return s < e

@st.cache_data(ttl=3600)
def load_prices(_tickers: List[str], start: dt.date, end: dt.date, interval: str, ma1: int, ma2: int) -> Dict[str, pd.DataFrame]:
    out: Dict[str, pd.DataFrame] = {}
    for t in _tickers:
        try:
            df = yf.download(
                t, start=start, end=end + dt.timedelta(days=1), interval=interval,
                auto_adjust=True, progress=False
            )
            if not df.empty:
                df.index = pd.to_datetime(df.index)
                df["MA1"] = df["Close"].rolling(ma1).mean()
                df["MA2"] = df["Close"].rolling(ma2).mean()
                out[t] = df
        except Exception as ex:
            st.warning(f"ä¸‹è¼‰ {t} å¤±æ•—ï¼š{ex}")
    return out

@st.cache_data(ttl=900)
def fetch_news(_tickers: List[str], limit_per_ticker: int = 20) -> pd.DataFrame:
    rows = []
    for t in _tickers:
        try:
            news_list = yf.Ticker(t).news or []
            for item in news_list[:limit_per_ticker]:
                title = item.get("title", "")
                link = item.get("link", "")
                provider = item.get("publisher", "")
                ts = item.get("providerPublishTime")
                ts = pd.to_datetime(ts, unit="s", utc=True).tz_convert("Asia/Taipei") if ts else None
                rows.append({"ticker": t, "time": ts, "provider": provider, "title": title, "link": link})
        except Exception as ex:
            st.warning(f"æŠ“å– {t} æ–°èå¤±æ•—ï¼š{ex}")
    df = pd.DataFrame(rows).sort_values("time", ascending=False).reset_index(drop=True)
    return df

@st.cache_resource(show_spinner=False)
def load_pipeline(name: str):
    # device="cpu" å¯åœ¨ç„¡ GPU çš„ç’°å¢ƒä¸‹é‹è¡Œï¼›è‹¥ä½¿ç”¨ CUDAï¼šdevice=0
    try:
        return pipeline("sentiment-analysis", model=name, device=-1)
    except Exception as ex:
        st.error(f"è¼‰å…¥æ¨¡å‹å¤±æ•—ï¼š{ex}")
        st.stop()

@st.cache_data(ttl=600)
def analyze_texts(texts: List[str], model_name: str) -> pd.DataFrame:
    if not texts:
        return pd.DataFrame(columns=["text", "label", "score"])
    clf = load_pipeline(model_name)
    results = clf(texts, truncation=True)
    # çµ±ä¸€æ¬„ä½
    rows = []
    for t, r in zip(texts, results):
        label = r.get("label", "")
        score = float(r.get("score", 0.0))
        rows.append({"text": t, "label": label, "score": score})
    return pd.DataFrame(rows)


# -----------------------------
# ä¸»å€å¡Šï¼šæ¨™é¡Œ
# -----------------------------

st.title("ğŸ“ˆ è‚¡åƒ¹èµ°å‹¢ + ğŸ—ï¸ è¼¿æƒ…åˆ†æ å„€è¡¨æ¿")

if not _valid_range(start_date, end_date):
    st.sidebar.error("é–‹å§‹æ—¥éœ€æ—©æ–¼çµæŸæ—¥")
    st.stop()

# è¼‰å…¥åƒ¹æ ¼è³‡æ–™
data = load_prices(tickers, start_date, end_date, interval, ma_1, ma_2)
if not data:
    st.info("æŸ¥ç„¡åƒ¹æ ¼è³‡æ–™ï¼Œè«‹æ›´æ›ä»£è™Ÿæˆ–æ™‚é–“å€é–“ã€‚")
    st.stop()

# -----------------------------
# åƒ¹æ ¼è¦–åœ–
# -----------------------------

if mode == "å¤šæ¨™çš„æ¯”è¼ƒ":
    st.subheader("å¤šæ¨™çš„èµ°å‹¢æ¯”è¼ƒ (åŸºæº–=100)")
    norm_df = pd.DataFrame()
    for t, df in data.items():
        if df.empty:
            continue
        series = (df["Close"] / df["Close"].iloc[0]) * 100
        norm_df[t] = series
    st.line_chart(norm_df)
else:
    t = tickers[0]
    df = data.get(t)
    st.subheader(f"{t} åƒ¹æ ¼èµ°å‹¢ï¼ˆ{interval}ï¼‰")
    fig = go.Figure()
    fig.add_trace(go.Candlestick(
        x=df.index, open=df["Open"], high=df["High"], low=df["Low"], close=df["Close"], name="OHLC"
    ))
    fig.add_trace(go.Scatter(x=df.index, y=df["MA1"], name=f"MA{ma_1}", mode="lines"))
    fig.add_trace(go.Scatter(x=df.index, y=df["MA2"], name=f"MA{ma_2}", mode="lines"))
    fig.update_layout(height=520, margin=dict(l=20, r=20, t=40, b=20), xaxis_title="æ—¥æœŸ", yaxis_title="åƒ¹æ ¼")
    st.plotly_chart(fig, use_container_width=True)

    if show_volume:
        vol = go.Figure()
        vol.add_trace(go.Bar(x=df.index, y=df["Volume"], name="Volume"))
        vol.update_layout(height=200, margin=dict(l=20, r=20, t=10, b=20))
        st.plotly_chart(vol, use_container_width=True)

    # æŒ‡æ¨™å¡ç‰‡
    col1, col2, col3, col4 = st.columns(4)
    last_close = df["Close"].iloc[-1]
    ret = ((df["Close"].iloc[-1] / df["Close"].iloc[0]) - 1) * 100
    hi_ = df["High"].max()
    lo_ = df["Low"].min()
    vol_std = df["Close"].pct_change().std() * (252 ** 0.5) * 100
    col1.metric("æœ€æ–°æ”¶ç›¤", f"{last_close:,.2f}")
    col2.metric("å€é–“å ±é…¬(%)", f"{ret:,.2f}")
    col3.metric("å€é–“æœ€é«˜", f"{hi_:,.2f}")
    col4.metric("å€é–“æœ€ä½", f"{lo_:,.2f}")
    st.caption(f"å¹´åŒ–æ³¢å‹•ç‡(è¿‘ä¼¼)ï¼š{vol_std:.2f}%")

    with st.expander("æŸ¥çœ‹åŸå§‹è³‡æ–™è¡¨ / ä¸‹è¼‰ CSV"):
        st.dataframe(df)
        csv = df.to_csv(index=True).encode("utf-8-sig")
        st.download_button(
            label="ä¸‹è¼‰ CSV", data=csv,
            file_name=f"{t}_{start_date}_{end_date}_{interval}.csv", mime="text/csv"
        )

# -----------------------------
# è¼¿æƒ…åˆ†æå€ï¼šä¾†è‡ª yfinance æ–°è + è‡ªè¨‚æ–‡å­—
# -----------------------------

st.markdown("---")
st.header("ğŸ—ï¸ è¼¿æƒ…åˆ†æ (Hugging Face)")

news_df = pd.DataFrame()
if max_items_news and max_items_news > 0:
    news_df = fetch_news(tickers, limit_per_ticker=max_items_news)
    if not news_df.empty:
        st.subheader("æœ€æ–°æ–°èæ¨™é¡Œ")
        st.dataframe(news_df[["ticker", "time", "provider", "title"]])

# å¾…åˆ†ææ–‡å­—é›†åˆï¼šæ–°èæ¨™é¡Œ + ä½¿ç”¨è€…è‡ªè¨‚
texts: List[str] = []
if not news_df.empty:
    texts.extend(news_df["title"].tolist())
if user_text.strip():
    texts.extend([line.strip() for line in user_text.splitlines() if line.strip()])

if texts:
    with st.spinner("æ¨¡å‹åˆ†æä¸­â€¦"):
        df_pred = analyze_texts(texts, model_name)

    # è‹¥æ˜¯ 1~5 æ˜Ÿæ¨¡å‹ï¼Œå°‡ label æ­£è¦åŒ–ç‚º Negative/Neutral/Positive
    def normalize_label(label: str) -> str:
        l = label.lower()
        # å¸¸è¦‹ï¼š'NEGATIVE'/'NEUTRAL'/'POSITIVE' æˆ– '1 star'...'5 stars'
        if "neg" in l or l.startswith("1") or l.startswith("2"):
            return "negative"
        if "neu" in l or l.startswith("3"):
            return "neutral"
        return "positive"

    df_pred["sentiment"] = df_pred["label"].map(normalize_label)

    st.subheader("æƒ…ç·’åˆ†ä½ˆ")
    counts = df_pred["sentiment"].value_counts().reset_index()
    counts.columns = ["sentiment", "count"]
    fig_bar = px.bar(counts, x="sentiment", y="count")
    fig_bar.update_layout(height=300, margin=dict(l=20, r=20, t=30, b=20))
    st.plotly_chart(fig_bar, use_container_width=True)

    st.subheader("é€å‰‡çµæœ")
    show_cols = ["text", "label", "score", "sentiment"]
    st.dataframe(df_pred[show_cols])

    # è‹¥æœ‰æ–°èè³‡æ–™ï¼Œåˆä½µå›ä¾†æºè¡¨
    if not news_df.empty:
        merged = news_df.copy()
        merged = merged.join(df_pred[["label", "score", "sentiment"]], how="left")
        with st.expander("æ–°èæƒ…ç·’æ˜ç´°èˆ‡ä¸‹è¼‰"):
            st.dataframe(merged[["time", "ticker", "provider", "title", "label", "score", "sentiment"]])
            csv2 = merged.to_csv(index=False).encode("utf-8-sig")
            st.download_button("ä¸‹è¼‰æ–°èæƒ…ç·’ CSV", csv2, "news_sentiment.csv", "text/csv")
else:
    st.info("æ²’æœ‰å¯åˆ†æçš„æ–‡å­—ã€‚è«‹åœ¨å´æ¬„è¼¸å…¥æ–‡å­—ï¼Œæˆ–é–‹å•Ÿã€åˆ†ææœ€æ–°æ–°èã€ã€‚")

# -----------------------------
# æ‰¹æ¬¡ä¸‹è¼‰ï¼ˆå¤šæ¨™çš„ï¼‰
# -----------------------------

with st.expander("æ‰¹æ¬¡ä¸‹è¼‰ï¼ˆæ‰€æœ‰è¼¸å…¥çš„æ¨™çš„ï¼‰"):
    if data:
        from io import BytesIO
        buff = BytesIO()
        with pd.ExcelWriter(buff, engine="xlsxwriter") as writer:
            for t, df in data.items():
                if df.empty:
                    continue
                df.to_excel(writer, sheet_name=t[:31])
        st.download_button(
            label="ä¸‹è¼‰å¤šæ¨™çš„ Excel",
            data=buff.getvalue(),
            file_name=f"prices_{start_date}_{end_date}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

# -----------------------------
# èªªæ˜
# -----------------------------

st.markdown(
    """
    **èªªæ˜**  
    - è³‡æ–™ä¾†æºï¼š`yfinance`ï¼ˆYahoo Financeï¼‰ï¼›æ–°èæ˜¯ä»¥ `yf.Ticker(...).news` æŠ“å–è¿‘æ³æ¨™é¡Œï¼ˆæœ‰äº›æ¨™çš„å¯èƒ½ç„¡æ–°èï¼‰ã€‚  
    - è¼¿æƒ…åˆ†æï¼šé è¨­ä½¿ç”¨ `cardiffnlp/twitter-xlm-roberta-base-sentiment`ï¼ˆå¤šèªè¨€ 3 é¡åˆ¥ï¼‰ï¼Œå¯åœ¨å´æ¬„æ›´æ›æ¨¡å‹ã€‚  
    - è‹¥ä½ çš„ç’°å¢ƒæœ‰ GPUï¼Œå¯ä¿®æ”¹ `load_pipeline` è£¡çš„ `device` åƒæ•¸ä»¥åŠ é€Ÿæ¨è«–ã€‚  
    - ä¼æ¥­æ‡‰ç”¨å»ºè­°ï¼šå¯å°‡è³‡æ–™ä¾†æºæ“´å……ç‚ºç¤¾ç¾¤è²¼æ–‡ã€è«–å£‡ã€å®¢æœå›é¥‹ï¼Œä¸¦ä»¥æ’ç¨‹æ‰¹æ¬¡å¯«å…¥è³‡æ–™åº«ï¼Œå†ç”±æ­¤ App åšå„€è¡¨å¯è¦–åŒ–ã€‚  
    """
)
